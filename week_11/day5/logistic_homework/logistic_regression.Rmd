---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(glmulti)
```
```{r}
orange_juice <- read_csv("data/orange_juice.csv") %>% janitor::clean_names()
dict <- read_csv("data/data_dict.txt")
head(orange_juice)
```
```{r}
orange_tidy <- orange_juice %>% 
  mutate(purchase_mm = ifelse(purchase == "MM", TRUE, FALSE)) %>% 
  select(-purchase) %>% 
  mutate(quarters = case_when(
    weekof_purchase <= 240 ~ "1st quarter",
    weekof_purchase >240 & weekof_purchase <=253 ~ "2nd quarter",
    weekof_purchase > 254 & weekof_purchase <= 266 ~ "3rd quarter",
    weekof_purchase > 266 ~ "4th quarter")) %>% 
  select(-weekof_purchase) %>% 
  mutate(store_id = as.factor(store_id)) %>% 
  mutate(special_ch = as.factor(special_ch)) %>% 
  mutate(special_mm = as.factor(special_mm)) %>% 
  mutate(store7 = as.factor(store7)) %>% 
  mutate(store = as.factor(store)) 

orange_tidy
```
```{r}
#it was found that there is 52 weeks which is a year
sort(unique(orange_juice$weekof_purchase))
278 - 227 = 51
```
```{r}
alias(purchase_mm ~ ., data = orange_tidy)
```
```{r}
orange_tidy <- orange_tidy %>% 
  select(-c(sale_price_mm, sale_price_ch, price_diff, store7, list_price_diff, store))

#all variables which has collinearity were removed
```

```{r}
orange_tidy
```
```{r}
#split the data into train and test
n_data <- nrow(orange_tidy)
test_index <- sample(1:n_data, size = n_data*0.2)

test  <- slice(orange_tidy, test_index)
train <- slice(orange_tidy, -test_index)
```


```{r}
glmulti_search_all_mains <- glmulti(
  purchase_mm ~ ., 
  data = train,
  level = 1,               # No interactions considered, main effects only
  method = "h",            # Exhaustive approach
  crit = "bic",            # BIC as criteria
  confsetsize = 10,        # Keep 10 best models
  plotty = F, 
  report = T,              # No plots, but provide interim reports
  fitfunction = "glm",     # glm function
  family = binomial(link = "logit")) # binomial family for logistic regression

summary(glmulti_search_all_mains)
```
```{r}
glmulti_search_previous_mains_one_pair <- glmulti(
  purchase_mm ~ 1 + price_ch + price_mm + disc_mm + loyal_ch + pct_disc_mm + 
    pct_disc_ch, 
  data = train,
  level = 2,               # Interactions considered
  method = "h",            # Exhaustive approach
  crit = "bic",            # BIC as criteria
  confsetsize = 10,        # Keep 10 best models
  marginality = TRUE,      # consider pairs only if both main effects in model
  minsize = 6,             # minsize, maxsize and marginality here force 
  maxsize = 6,             # inclusion of a single pair beyond the five main effects
  plotty = F, 
  report = T,              # No plots, but provide interim reports
  fitfunction = "glm",     # glm function
  family = binomial(link = "logit")) # binomial family for logistic regression

summary(glmulti_search_previous_mains_one_pair)
```
The best model is :
"purchase_mm ~ 1 + price_ch + price_mm + disc_mm + loyal_ch + "
 pct_disc_mm + pct_disc_ch" 
```{r}
model <- glm(purchase_mm ~ price_ch + price_mm + disc_mm + loyal_ch + 
 pct_disc_mm + pct_disc_ch, data = train, family = binomial(link = "logit"))

summary(model)
```

```{r}
library(broom)
glance(model)
```
```{r}
library(modelr)
model_predictions <- train %>% 
  add_predictions(model, type = "response")

head(model_predictions)

roc_train <- model_predictions %>% 
  roc(response = purchase_mm, predictor = pred)
```
```{r}
library(pROC)

auc(roc_train)
```
```{r}
library(caret)
orange_tidy <- orange_tidy %>% 
  mutate(purchase_mm = as_factor(if_else(TRUE, "t", "f"))) 
train_control <- trainControl(method = "repeatedcv", 
                              number = 5,
                              repeats = 100,
                              savePredictions = TRUE, 
                              classProbs = TRUE, 
                              summaryFunction = twoClassSummary)
```
```{r}
model_cv <- train(purchase_mm ~ price_ch + price_mm + disc_mm + loyal_ch + 
 pct_disc_mm + pct_disc_ch,
               data = orange_tidy,
               trControl = train_control,
               method = "glm",
               family = binomial(link = 'logit'))
```






